import joblib
import streamlit as st

def remove_number(sentence):
    return ' '.join(word for word in sentence.split() if not word.isdigit())

def remove_stop_words(sentence, stop_words_file):
    with open(stop_words_file, 'r', encoding='utf-8') as file:
        stop_words = file.read().split('\n')
    return ' '.join(word for word in sentence.split() if word not in stop_words)

def unconvert(category_dict, value):
    return category_dict.get(value, "KhÃ´ng xÃ¡c Ä‘á»‹nh")

def run():
    model, tfidf_vectorizer, category_dict = joblib.load('Model/model.joblib')

    st.set_page_config(page_title="Há»‡ thá»‘ng phÃ¢n loáº¡i vÄƒn báº£n", page_icon="ğŸ‘‹")

    st.write("# Há»‡ thá»‘ng phÃ¢n loáº¡i vÄƒn báº£n")

    sentence = st.text_input('Nháº­p tiÃªu Ä‘á» vÄƒn báº£n:')

    if st.button('Submit', type='primary') and sentence:
        processed_sentence = remove_number(sentence.lower())
        processed_sentence = remove_stop_words(processed_sentence, 'Data/vietnamese_stop_words.txt')
        vectorized_sentence = tfidf_vectorizer.transform([processed_sentence])
        category = model.predict(vectorized_sentence)[0]  # Láº¥y chá»‰ sá»‘ Ä‘áº§u tiÃªn vÃ¬ predict tráº£ vá» má»™t máº£ng
        category_name = unconvert(category_dict, category)
        st.title(f'Vá»›i tiÃªu Ä‘á» trÃªn, thá»ƒ loáº¡i cá»§a vÄƒn báº£n sáº½ thuá»™c: {category_name}')

if __name__ == "__main__":
    run()
